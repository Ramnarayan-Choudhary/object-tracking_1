{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramnarayan-Choudhary/object-tracking_1/blob/main/3_Object_Detection_and_MOT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX1esx9JMpFR"
      },
      "source": [
        "# **Multiple Object Tracking with PyTorch**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "**Reference**\n",
        "\n",
        "\n",
        "*   Object Detection with Faster R-CNN: https://www.learnopencv.com/faster-r-cnn-object-detection-with-pytorch/\n",
        "*   Simple Online and Realtime Tracking (SORT) algorithm for object ID tracking: https://arxiv.org/abs/1602.00763\n",
        "\n",
        "\n",
        "**Question**\n",
        ": What is Multiple Object Tracking?\n",
        "- Object tracking is one of the tasks in computer vision, which is detecting an object and searching for that object in a video or a series of images (actually both meaning the same thing).\n",
        "- Surveillance cameras in public places for spotting suspicious activities or crimes, and a computer system called 'Hawk-eye' for tracking the trajectory of the ball in various sports are typical examples of applying object tracking in a real life.\n",
        "\n",
        "\n",
        "**Goals**\n",
        "\n",
        "\n",
        "1. We will use MOT17Det Dataset\n",
        "2. First part: Object Detection with **Faster R-CNN**\n",
        "3. Second part: Multiple Object(ID) Tracking with  **Simple Online and Realtime Tracking (SORT)** algorithm\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzmQhgb43MMg"
      },
      "source": [
        "**0. Preparation**\n",
        "\n",
        "\n",
        "*   For your convenience, it is recommended to mount your Google Drive first.\n",
        "*   Then create extra space for this tutorial in there.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnS6Q7M7C2VP"
      },
      "source": [
        "from google.colab import drive\n",
        "root = '/content/drive/'\n",
        "drive.mount(root)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf8jnmft4v7Q"
      },
      "source": [
        "# Making Directory\n",
        "\n",
        "import os\n",
        "from os.path import join\n",
        "\n",
        "mot = \"My Drive/Colab Notebooks/MOT/\"   # a custom path. you can change if you want to\n",
        "MOT_PATH = join(root,mot)\n",
        "!mkdir \"{MOT_PATH}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zHl8FW6p1DI"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**1. Dataset**\n",
        "\n",
        "\n",
        "*   https://motchallenge.net/ : MOT17Det Dataset for Pedestrian Detection Challenge\n",
        "*   We will only use MOT17-09 dataset for our task.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oHlCPGp6xZx"
      },
      "source": [
        "# Remove unwanted data for drive volume issue (optional)\n",
        "\n",
        "!cd \"{MOT_PATH}\";rm -rf test\n",
        "!cd \"{MOT_PATH}\";rm -rf train/MOT17-02;rm -rf train/MOT17-04;rm -rf train/MOT17-05\n",
        "!cd \"{MOT_PATH}\";rm -rf train/MOT17-10;rm -rf train/MOT17-11;rm -rf train/MOT17-13"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MOT_PATH"
      ],
      "metadata": {
        "id": "68gd-4kWW_Ex",
        "outputId": "63d0ccd1-d020-4bd6-edcb-c6fd2cac6ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct_3R8Nf-GlT"
      },
      "source": [
        "import sys\n",
        "from os.path import join\n",
        "\n",
        "MOT_PATH = ''\n",
        "motdata = join(MOT_PATH, 'train/MOT17-13/img1/000750.jpg ')\n",
        "sys.path.append(motdata)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Set the paths for the dataset\n",
        "MOT_PATH = \"/content/dataset\"  # Change this path as per your requirement\n",
        "ZIP_PATH = os.path.join(MOT_PATH, \"MOT17Det.zip\")\n",
        "\n",
        "# Download and extract the dataset\n",
        "!wget -P \"{MOT_PATH}\" https://motchallenge.net/data/MOT17Det.zip\n",
        "!unzip -q \"{ZIP_PATH}\" -d \"{MOT_PATH}\"\n",
        "\n",
        "# Verify the extraction\n",
        "extracted_folder = os.path.join(MOT_PATH, \"MOT17Det\")\n",
        "if os.path.exists(extracted_folder):\n",
        "    print(\"Dataset extracted successfully.\")\n",
        "else:\n",
        "    print(\"Dataset extraction failed.\")\n"
      ],
      "metadata": {
        "id": "h5U8QA9BYZ_a",
        "outputId": "368d7f97-c728-4f33-c233-90974ff7e693",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-06 08:47:05--  https://motchallenge.net/data/MOT17Det.zip\n",
            "Resolving motchallenge.net (motchallenge.net)... 131.159.19.34, 2a09:80c0:18::1034\n",
            "Connecting to motchallenge.net (motchallenge.net)|131.159.19.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1952547113 (1.8G) [application/zip]\n",
            "Saving to: ‘/content/dataset/MOT17Det.zip.1’\n",
            "\n",
            "MOT17Det.zip.1      100%[===================>]   1.82G  11.9MB/s    in 2m 46s  \n",
            "\n",
            "2023-07-06 08:49:52 (11.2 MB/s) - ‘/content/dataset/MOT17Det.zip.1’ saved [1952547113/1952547113]\n",
            "\n",
            "[/content/dataset/MOT17Det.zip]\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/dataset/MOT17Det.zip or\n",
            "        /content/dataset/MOT17Det.zip.zip, and cannot find /content/dataset/MOT17Det.zip.ZIP, period.\n",
            "Dataset extraction failed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_evT8k1S9GQU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "85cdee14-e0e6-42df-e83d-66d56901750e"
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# MOT_PATH = ''  # Replace with the actual path to your MOT dataset directory\n",
        "# motdata = os.path.join(MOT_PATH, 'train/MOT17-09/img1/')\n",
        "\n",
        "list_motdata = os.listdir(motdata)\n",
        "list_motdata.sort()\n",
        "\n",
        "img_ex_path = os.path.join(motdata, list_motdata[0])\n",
        "img_ex_origin = cv2.imread(img_ex_path)\n",
        "img_ex = cv2.cvtColor(img_ex_origin, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(img_ex)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7dd8830ba74d>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# motdata = os.path.join(MOT_PATH, 'train/MOT17-09/img1/')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlist_motdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmotdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mlist_motdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train/MOT17-13/img1/000750.jpg '"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvuU_xZjqrJd"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**2. Object Detection with Faster R-CNN**\n",
        "\n",
        "*  We will use a pretrained Faster R-CNN model using ResNet50 as a backbone with FPN.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IEdaeDV6xfZ"
      },
      "source": [
        "# Import required packages/modules first\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaFru4rA6xrr"
      },
      "source": [
        "# Download the pretrained Faster R-CNN model from torchvision\n",
        "\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBcUWr2W9Tfe"
      },
      "source": [
        "# Define the class names given by PyTorch's official Docs\n",
        "\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
        "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
        "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAbS5uwE9vd0"
      },
      "source": [
        "# Defining a function for get a prediction result from the model\n",
        "\n",
        "def get_prediction(img_path, threshold):\n",
        "  img = Image.open(img_path) # Load the image\n",
        "  transform = T.Compose([T.ToTensor()]) # Defing PyTorch Transform\n",
        "  img = transform(img) # Apply the transform to the image\n",
        "  pred = model([img]) # Pass the image to the model\n",
        "  pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].numpy())] # Get the Prediction Score\n",
        "  pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().numpy())] # Bounding boxes\n",
        "  pred_score = list(pred[0]['scores'].detach().numpy())\n",
        "  pred_t = [pred_score.index(x) for x in pred_score if x > threshold][-1] # Get list of index with score greater than threshold.\n",
        "  pred_boxes = pred_boxes[:pred_t+1]\n",
        "  pred_class = pred_class[:pred_t+1]\n",
        "  return pred_boxes, pred_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa4XIuLH6xoa"
      },
      "source": [
        "# Defining a api function for object detection\n",
        "\n",
        "def object_detection_api(img_path, threshold=0.5, rect_th=3, text_size=1.5, text_th=3):\n",
        "\n",
        "  boxes, pred_cls = get_prediction(img_path, threshold) # Get predictions\n",
        "  img = cv2.imread(img_path) # Read image with cv2\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
        "  for i in range(len(boxes)):\n",
        "    cv2.rectangle(img, boxes[i][0], boxes[i][1],color=(0, 255, 0), thickness=rect_th) # Draw Rectangle with the coordinates\n",
        "    cv2.putText(img,pred_cls[i], boxes[i][0],  cv2.FONT_HERSHEY_SIMPLEX, text_size, (0,255,0),thickness=text_th) # Write the prediction class\n",
        "  plt.figure(figsize=(15,20)) # display the output image\n",
        "  plt.imshow(img)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDlyeXSXHMLo"
      },
      "source": [
        "# Example: After detection\n",
        "object_detection_api(img_ex_path,threshold=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X8gXp0eInzV"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "*   The picture above is an example of applying Detection Network (in our case, Faster R-CNN).\n",
        "*   Since the purpose of dataset we are using is 'tracking', you can see that most of the detected classes are 'person'.\n",
        "*   We need a prediction result (bbs offset, class label, pred scores) for all the images.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCelLE4jq8ye"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**3. Object ID Tracking with SORT**\n",
        "\n",
        "\n",
        "*   Simple Online and Realtime Tracking (SORT) algorithm for object ID tracking\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1WuiRXsHMPG"
      },
      "source": [
        "# Git clone: SORT Algorithm\n",
        "\n",
        "!cd \"{MOT_PATH}\";git clone https://github.com/abewley/sort.git\n",
        "\n",
        "sort = join(MOT_PATH,'sort/')\n",
        "sys.path.append(sort)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byjLd9LkKTux"
      },
      "source": [
        "# requirement for sort\n",
        "!cd \"{sort}\";pip install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rk2pt2SyuH9s"
      },
      "source": [
        "# Optional: if error occurs, you might need to re-install scikit-image and imgaug\n",
        "\n",
        "!pip uninstall scikit-image\n",
        "!pip uninstall imgaug\n",
        "!pip install imgaug\n",
        "!pip install -U scikit-image\n",
        "\n",
        "import skimage\n",
        "print(skimage.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nfV0kTkMmsd"
      },
      "source": [
        "# Detection information on all the images is well-refined as a json file, which is available at our course git repo\n",
        "\n",
        "!cd \"{MOT_PATH}\";git clone https://github.com/mlvlab/COSE474.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdErbmxk96w1"
      },
      "source": [
        "import json\n",
        "import collections\n",
        "from pprint import pprint\n",
        "from sort import *\n",
        "\n",
        "jsonpath = join(MOT_PATH,'COSE474/3_MOT_detinfo.json')\n",
        "\n",
        "with open(jsonpath) as data_file:\n",
        "   data = json.load(data_file)\n",
        "odata = collections.OrderedDict(sorted(data.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eONi2h58yKjD"
      },
      "source": [
        "# Let's check out downloaded json file\n",
        "\n",
        "pprint(odata)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnsyoUpmz42L"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "*   For each image, bbs offset, class label, pred scores are all annotated.\n",
        "*   Labels are annotated as a number - not a word, and for further information, go to the website below.\n",
        "* https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUB25un4yJsX"
      },
      "source": [
        "img_path = motdata    # img root path\n",
        "\n",
        "# Making new directory for saving results\n",
        "save_path = join(MOT_PATH,'save/')\n",
        "!mkdir \"{save_path}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k9vAOQQ960r"
      },
      "source": [
        "mot_tracker = Sort()      # Tracker using SORT Algorithm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLvfa1Ls964o"
      },
      "source": [
        "for key in odata.keys():\n",
        "    arrlist = []\n",
        "    det_img = cv2.imread(os.path.join(img_path, key))\n",
        "    overlay = det_img.copy()\n",
        "    det_result = data[key]\n",
        "\n",
        "    for info in det_result:\n",
        "        bbox = info['bbox']\n",
        "        labels = info['labels']\n",
        "        scores = info['scores']\n",
        "        templist = bbox+[scores]\n",
        "\n",
        "        if labels == 1: # label 1 is a person in MS COCO Dataset\n",
        "            arrlist.append(templist)\n",
        "\n",
        "    track_bbs_ids = mot_tracker.update(np.array(arrlist))\n",
        "\n",
        "    mot_imgid = key.replace('.jpg','')\n",
        "    newname = save_path + mot_imgid + '_mot.jpg'\n",
        "    print(mot_imgid)\n",
        "\n",
        "    for j in range(track_bbs_ids.shape[0]):\n",
        "        ele = track_bbs_ids[j, :]\n",
        "        x = int(ele[0])\n",
        "        y = int(ele[1])\n",
        "        x2 = int(ele[2])\n",
        "        y2 = int(ele[3])\n",
        "        track_label = str(int(ele[4]))\n",
        "        cv2.rectangle(det_img, (x, y), (x2, y2), (0, 255, 255), 4)\n",
        "        cv2.putText(det_img, '#'+track_label, (x+5, y-10), 0,0.6,(0,255,255),thickness=2)\n",
        "\n",
        "    cv2.imwrite(newname,det_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyVRJJLMnNGo"
      },
      "source": [
        "\n",
        "---\n",
        "It's all done!\n",
        "\n",
        "\n",
        "*   Finally, you can get a sequence of image with each Tracking ID for every detected person.\n",
        "*   Check '3_MOT_result.gif' for whole demo experience.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    }
  ]
}